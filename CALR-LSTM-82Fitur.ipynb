{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"config=3\n# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"../input/fp2021/data.py\", dst = \"../working/data.py\")\ncopyfile(src = \"../input/fp2021/utils.py\", dst = \"../working/utils.py\")\ncopyfile(src = \"../input/fp2021/training.py\", dst = \"../working/training.py\")\ncopyfile(src = \"../input/fp2021/layers.py\", dst = \"../working/layers.py\")\n#copyfile(src = \"../input/notes1/weights2.npy\", dst = \"../working/weights2.npy\")\n# import all our functions\n#from data import load_data","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:14.051476Z","iopub.execute_input":"2021-12-29T16:28:14.051837Z","iopub.status.idle":"2021-12-29T16:28:14.109118Z","shell.execute_reply.started":"2021-12-29T16:28:14.051742Z","shell.execute_reply":"2021-12-29T16:28:14.108173Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'../working/layers.py'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install pickle5\nimport pickle5 as pickle\nimport csv\nimport calendar\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import  MultipleLocator, FormatStrFormatter\nfrom scipy.interpolate import splrep\nfrom IPython.core.display import display_html\nfrom keras.models import load_model\nfrom utils import np_haversine, density_map, get_clusters, plot_embeddings\nfrom data import load_data\n#from training import start_new_session, process_features, create_model\n\n# Display plots inline\n%matplotlib inline\n\n# Fix random seed for reproducibility\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:14.110586Z","iopub.execute_input":"2021-12-29T16:28:14.110829Z","iopub.status.idle":"2021-12-29T16:28:32.233501Z","shell.execute_reply.started":"2021-12-29T16:28:14.110800Z","shell.execute_reply":"2021-12-29T16:28:32.232522Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pickle5\n  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n     |████████████████████████████████| 256 kB 5.2 MB/s            \n\u001b[?25hInstalling collected packages: pickle5\nSuccessfully installed pickle5-0.0.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def start_new_session():\n    \"\"\"\n    Starts a new Tensorflow session.\n    \"\"\"\n    \n    # Make sure the session only uses the GPU memory that it actually needs\n    config = tf.compat.v1.ConfigProto()\n    config.gpu_options.allow_growth = True\n    \n    session = tf.compat.v1.Session(config=config, graph=tf.compat.v1.get_default_graph())\n    tf.compat.v1.keras.backend.set_session(session)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:32.234653Z","iopub.execute_input":"2021-12-29T16:28:32.234886Z","iopub.status.idle":"2021-12-29T16:28:32.241036Z","shell.execute_reply.started":"2021-12-29T16:28:32.234856Z","shell.execute_reply":"2021-12-29T16:28:32.240248Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"clusters_cache = '/kaggle/input/fp2021/clusters.npy'\nclusters=np.load(clusters_cache, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:32.243731Z","iopub.execute_input":"2021-12-29T16:28:32.243966Z","iopub.status.idle":"2021-12-29T16:28:32.269360Z","shell.execute_reply.started":"2021-12-29T16:28:32.243940Z","shell.execute_reply":"2021-12-29T16:28:32.268493Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"metadata_cache = '/kaggle/input/fp2021/metadata.pickle'\nwith open(metadata_cache, 'rb') as handle:\n    metadata = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:32.270723Z","iopub.execute_input":"2021-12-29T16:28:32.270997Z","iopub.status.idle":"2021-12-29T16:28:32.280362Z","shell.execute_reply.started":"2021-12-29T16:28:32.270963Z","shell.execute_reply":"2021-12-29T16:28:32.279722Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"file='/kaggle/input/fp2021/train0.npy'\ntrain0=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train1.npy'\ntrain1=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train2.npy'\ntrain2=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train3.npy'\ntrain3=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train4.npy'\ntrain4=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train5.npy'\ntrain5=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/train6.npy'\ntrain6=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\ntrain=[train0,train1,train2,train3,train4,train5,train6]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:32.281823Z","iopub.execute_input":"2021-12-29T16:28:32.282219Z","iopub.status.idle":"2021-12-29T16:28:34.749363Z","shell.execute_reply.started":"2021-12-29T16:28:32.282180Z","shell.execute_reply":"2021-12-29T16:28:34.748482Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"file='/kaggle/input/fp2021/validation0.npy'\nvalidation0=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation1.npy'\nvalidation1=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation2.npy'\nvalidation2=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation3.npy'\nvalidation3=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation4.npy'\nvalidation4=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation5.npy'\nvalidation5=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/fp2021/validation6.npy'\nvalidation6=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nvalidation=[validation0,validation1,validation2,validation3,validation4,validation5,validation6]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:34.750641Z","iopub.execute_input":"2021-12-29T16:28:34.750892Z","iopub.status.idle":"2021-12-29T16:28:35.294424Z","shell.execute_reply.started":"2021-12-29T16:28:34.750862Z","shell.execute_reply":"2021-12-29T16:28:35.293402Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"metadata_cache = '/kaggle/input/fp2021/metadata.pickle'\nwith open(metadata_cache, 'rb') as handle:\n    metadata = pickle.load(handle)\ntl_cache = '/kaggle/input/fp2021/train-labels.npy'\nvl_cache = '/kaggle/input/fp2021/validation-labels.npy'\ntrain_labels=np.load(tl_cache, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\nvalidation_labels=np.load(vl_cache, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:35.295838Z","iopub.execute_input":"2021-12-29T16:28:35.296088Z","iopub.status.idle":"2021-12-29T16:28:35.574449Z","shell.execute_reply.started":"2021-12-29T16:28:35.296059Z","shell.execute_reply":"2021-12-29T16:28:35.573588Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#import pickle\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import scale\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD, Adam, Adagrad\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.core import Dense, Reshape, Activation, Dropout\nfrom keras.layers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom utils import tf_haversine\nfrom data import load_data\nfrom utils import get_clusters\nfrom keras.models import Model\n\nfrom tensorflow.compat.v1.keras.layers import LSTM   # CuDNNLSTM\nimport sys\nsys.path.append('..')  # add parent directory to Python path for layers.py access\nfrom layers import Attention, SelfAttention\n\ndef create_model(metadata,clusters,config):\n    \"\"\"\n    Creates all the layers for our neural network model.\n    \"\"\"\n      \n    # Arbitrary dimension for all embeddings\n    embedding_dim = 10\n\n    # Quarter hour of the day embedding\n    embed_quarter_hour = Sequential()\n    embed_quarter_hour.add(Embedding(metadata['n_quarter_hours'], embedding_dim, input_length=1))\n    embed_quarter_hour.add(Reshape((embedding_dim,1)))\n\n    # Day of the week embedding\n    embed_day_of_week = Sequential()\n    embed_day_of_week.add(Embedding(metadata['n_days_per_week'], embedding_dim, input_length=1))\n    embed_day_of_week.add(Reshape((embedding_dim,1)))\n\n    # Week of the year embedding\n    embed_week_of_year = Sequential()\n    embed_week_of_year.add(Embedding(metadata['n_weeks_per_year'], embedding_dim, input_length=1))\n    embed_week_of_year.add(Reshape((embedding_dim,1)))\n\n    # Client ID embedding\n    embed_client_ids = Sequential()\n    embed_client_ids.add(Embedding(metadata['n_client_ids'], embedding_dim, input_length=1))\n    embed_client_ids.add(Reshape((embedding_dim,1)))\n\n    # Taxi ID embedding\n    embed_taxi_ids = Sequential()\n    embed_taxi_ids.add(Embedding(metadata['n_taxi_ids'], embedding_dim, input_length=1))\n    embed_taxi_ids.add(Reshape((embedding_dim,1)))\n\n    # Taxi stand ID embedding\n    embed_stand_ids = Sequential()\n    embed_stand_ids.add(Embedding(metadata['n_stand_ids'], embedding_dim, input_length=1))\n    embed_stand_ids.add(Reshape((embedding_dim,1)))\n    \n    # GPS coordinates (5 first lat/long and 5 latest lat/long, therefore 20 values)\n    coords = Sequential()\n    coords.add(Dense(1, input_dim=20))\n\n    # Merge all the inputs into a single input layer\n    mergedOut = Add()([embed_quarter_hour.output,\n                embed_day_of_week.output,\n                embed_week_of_year.output,\n                embed_client_ids.output,\n                embed_taxi_ids.output,\n                embed_stand_ids.output,\n                coords.output])\n    \n    #encoder_output, hidden_state, cell_state = LSTM(50, activation='tanh',input_shape=(None,None, 1),\n    #                                                return_sequences=True,return_state=True)(mergedOut)\n    #attention_input = [encoder_output, hidden_state]\n    if config != 0:\n        encoder_output, hidden_state, cell_state = LSTM(units=200,\n                                                         return_sequences=True\n                                                        ,return_state=True#,input_shape=(50,1)\n                                                       )(mergedOut)\n        attention_input = [encoder_output, hidden_state]\n    else:\n        encoder_output = LSTM(units=64)(mergedOut)\n\n    # Optional Attention Mechanisms\n    if config == 1:\n        encoder_output, attention_weights = SelfAttention(size=64,\n                                                      num_hops=10,\n                                                      use_penalization=False)(encoder_output)\n    elif config == 2:\n        encoder_output, attention_weights = Attention(context='many-to-one',\n                                                  alignment_type='global')(attention_input)\n        encoder_output = Flatten()(encoder_output)\n    elif config == 3:\n        encoder_output, attention_weights = Attention(context='many-to-one',\n                                                  alignment_type='local-m',\n                                                  window_width=10,\n                                                  score_function='general')(attention_input)\n        encoder_output = Flatten()(encoder_output)\n        \n    \n    #encoder_output=Dense(1)(encoder_output)\n    # Determine cluster probabilities using softmax\n    mergedOut=Dense(len(clusters))(encoder_output)\n    mergedOut=Activation('softmax')(mergedOut)\n\n    # Final activation layer: calculate the destination as the weighted mean of cluster coordinates\n    cast_clusters = K.cast_to_floatx(clusters)\n    def destination(probabilities):\n        return tf.matmul(probabilities, cast_clusters)\n    mergedOut=Activation(destination)(mergedOut)\n\n    newModel = Model([embed_quarter_hour.input,\n                embed_day_of_week.input,\n                embed_week_of_year.input,\n                embed_client_ids.input,\n                embed_taxi_ids.input,\n                embed_stand_ids.input,\n                coords.input], mergedOut)\n    #use lists if you want more than one input or output  \n    \n    # Compile the model\n    optimizer = SGD(lr=0.1, momentum=0.9, clipvalue=1.)  # Use `clipvalue` to prevent exploding gradients\n\n    newModel.compile(loss=tf_haversine, optimizer=optimizer)\n    \n    return newModel","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:35.575574Z","iopub.execute_input":"2021-12-29T16:28:35.575789Z","iopub.status.idle":"2021-12-29T16:28:36.173636Z","shell.execute_reply.started":"2021-12-29T16:28:35.575765Z","shell.execute_reply":"2021-12-29T16:28:36.172693Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model=create_model(metadata,clusters,config)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:36.177094Z","iopub.execute_input":"2021-12-29T16:28:36.177515Z","iopub.status.idle":"2021-12-29T16:28:38.104868Z","shell.execute_reply.started":"2021-12-29T16:28:36.177467Z","shell.execute_reply":"2021-12-29T16:28:38.103791Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\nUser settings:\n\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n   KMP_BLOCKTIME=0\n   KMP_DUPLICATE_LIB_OK=True\n   KMP_INIT_AT_FORK=FALSE\n   KMP_SETTINGS=1\n   KMP_WARNINGS=0\n\nEffective settings:\n\n   KMP_ABORT_DELAY=0\n   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n   KMP_ALIGN_ALLOC=64\n   KMP_ALL_THREADPRIVATE=128\n   KMP_ATOMIC_MODE=2\n   KMP_BLOCKTIME=0\n   KMP_CPUINFO_FILE: value is not defined\n   KMP_DETERMINISTIC_REDUCTION=false\n   KMP_DEVICE_THREAD_LIMIT=2147483647\n   KMP_DISP_NUM_BUFFERS=7\n   KMP_DUPLICATE_LIB_OK=true\n   KMP_ENABLE_TASK_THROTTLING=true\n   KMP_FORCE_REDUCTION: value is not defined\n   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n   KMP_FORKJOIN_BARRIER='2,2'\n   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_GTID_MODE=3\n   KMP_HANDLE_SIGNALS=false\n   KMP_HOT_TEAMS_MAX_LEVEL=1\n   KMP_HOT_TEAMS_MODE=0\n   KMP_INIT_AT_FORK=true\n   KMP_LIBRARY=throughput\n   KMP_LOCK_KIND=queuing\n   KMP_MALLOC_POOL_INCR=1M\n   KMP_NUM_LOCKS_IN_BLOCK=1\n   KMP_PLAIN_BARRIER='2,2'\n   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_REDUCTION_BARRIER='1,1'\n   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n   KMP_SCHEDULE='static,balanced;guided,iterative'\n   KMP_SETTINGS=true\n   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n   KMP_STACKOFFSET=64\n   KMP_STACKPAD=0\n   KMP_STACKSIZE=8M\n   KMP_STORAGE_MAP=false\n   KMP_TASKING=2\n   KMP_TASKLOOP_MIN_TASKS=0\n   KMP_TASK_STEALING_CONSTRAINT=1\n   KMP_TEAMS_THREAD_LIMIT=4\n   KMP_TOPOLOGY_METHOD=all\n   KMP_USE_YIELD=1\n   KMP_VERSION=false\n   KMP_WARNINGS=false\n   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n   OMP_ALLOCATOR=omp_default_mem_alloc\n   OMP_CANCELLATION=false\n   OMP_DEFAULT_DEVICE=0\n   OMP_DISPLAY_AFFINITY=false\n   OMP_DISPLAY_ENV=false\n   OMP_DYNAMIC=false\n   OMP_MAX_ACTIVE_LEVELS=1\n   OMP_MAX_TASK_PRIORITY=0\n   OMP_NESTED: deprecated; max-active-levels-var=1\n   OMP_NUM_THREADS: value is not defined\n   OMP_PLACES: value is not defined\n   OMP_PROC_BIND='intel'\n   OMP_SCHEDULE='static'\n   OMP_STACKSIZE=8M\n   OMP_TARGET_OFFLOAD=DEFAULT\n   OMP_THREAD_LIMIT=2147483647\n   OMP_WAIT_POLICY=PASSIVE\n   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n\n2021-12-29 16:28:36.223595: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustCallback(tf.keras.callbacks.Callback):\n    def on_train_end(self, logs=None):\n        global training_finished\n        training_finished = True\n    def on_epoch_end(self, epoch, logs=None):\n        z=len(f)\n        file_path=\"../working/Newweights\"+str(z)\n        weight=model.get_weights()\n        np.save(file_path, weight)\n        f.append(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:38.106446Z","iopub.execute_input":"2021-12-29T16:28:38.106759Z","iopub.status.idle":"2021-12-29T16:28:38.115166Z","shell.execute_reply.started":"2021-12-29T16:28:38.106714Z","shell.execute_reply":"2021-12-29T16:28:38.114013Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class MyCallback(tf.keras.callbacks.Callback):\n    def on_train_end(self, logs=None):\n        global training_finished\n        training_finished = True\n    def on_epoch_end(self, epoch, logs=None):\n        z=len(e)\n        if z>len(g):\n            a=model.history.history['val_loss'][z-len(g)-1]\n            b=model.history.history['loss'][z-len(g)-1]\n            c=float(a)-float(b)\n            if c<0:\n                print(\"Sebelumnya Underfitting\")\n            else:\n                print(\"Sebelumnya Overfitting\")\n        e.append(0)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:38.116643Z","iopub.execute_input":"2021-12-29T16:28:38.116990Z","iopub.status.idle":"2021-12-29T16:28:38.129109Z","shell.execute_reply.started":"2021-12-29T16:28:38.116945Z","shell.execute_reply":"2021-12-29T16:28:38.128056Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"e=[]\nf=[]\ng=[]\nh=[]\nfor i in range(88):\n    f.append(0)\n    e.append(0)\n    g.append(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:38.130895Z","iopub.execute_input":"2021-12-29T16:28:38.131406Z","iopub.status.idle":"2021-12-29T16:28:38.145051Z","shell.execute_reply.started":"2021-12-29T16:28:38.131359Z","shell.execute_reply":"2021-12-29T16:28:38.144115Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"file='../input/latl82fiturlocm/Newweights'+str(len(g)-1)+'.npy'\ny=np.load(file,allow_pickle=True)\nmodel.set_weights(y)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:38.148038Z","iopub.execute_input":"2021-12-29T16:28:38.148355Z","iopub.status.idle":"2021-12-29T16:28:39.081326Z","shell.execute_reply.started":"2021-12-29T16:28:38.148298Z","shell.execute_reply":"2021-12-29T16:28:39.080276Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Estimate the GPS clusters\nprint(\"Estimating clusters...\")\n#clusters = get_clusters(data.train_labels)\nn_epochs=100\nbatch_size=200\nsave_prefix='mymodel'\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:39.082582Z","iopub.execute_input":"2021-12-29T16:28:39.082820Z","iopub.status.idle":"2021-12-29T16:28:39.088595Z","shell.execute_reply.started":"2021-12-29T16:28:39.082793Z","shell.execute_reply":"2021-12-29T16:28:39.087596Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Estimating clusters...\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, CSVLogger\nfrom keras.callbacks import EarlyStopping\n \ncallbacks = []\nif save_prefix is not None:\n        # Save the model's intermediary weights to disk after each epoch\n    file_path=\"cache/%s-{epoch:03d}-{val_loss:.4f}.hdf5\" % save_prefix\n    checkpoint = ModelCheckpoint(file_path,monitor='val_loss',mode='auto',save_weights_only=True,verbose=0)\n    #checkpoint = weight_save(model.get_weights(),b)\n    callbacks.append(checkpoint)\n    #callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', mode='min', save_weights_only=True, verbose=1))\n    #callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', verbose=0, save_best_only=False, mode='auto'))\n    #model.fit(X_train,y_train,batch_size=batch_size,nb_epoch=nb_epoch,callbacks=[weight_save_callback])\n#g.append(0)\n#epoch>1\n#first epoch\n#saver = weight_save(model.get_weights(),b)   \n#es = EarlyStopping(monitor='val_loss', patience=0, verbose=1)\narc='AttenLSTMfitur91-b200-'+str(len(g))+'.log'\ncsv_logger = CSVLogger(arc, separator=',', append=False)\nprint(\"Creating model...\")\nstart_new_session()\nprint(\"Train model...\")\nhistory=model.fit(train, train_labels,\n        initial_epoch=len(g),epochs=100, batch_size=batch_size,\n        validation_data=(validation, validation_labels)\n        ,callbacks=[csv_logger,CustCallback(),MyCallback()])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:28:39.089964Z","iopub.execute_input":"2021-12-29T16:28:39.090204Z","iopub.status.idle":"2021-12-29T21:23:53.966071Z","shell.execute_reply.started":"2021-12-29T16:28:39.090176Z","shell.execute_reply":"2021-12-29T21:23:53.964338Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Creating model...\n","output_type":"stream"},{"name":"stderr","text":"2021-12-29 16:28:39.101746: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Train model...\n","output_type":"stream"},{"name":"stderr","text":"2021-12-29 16:28:39.799582: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89/100\n6578/6578 [==============================] - 1478s 224ms/step - loss: 1.9230 - val_loss: 2.0060\nEpoch 90/100\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  return array(a, dtype, copy=False, order=order, subok=True)\n","output_type":"stream"},{"name":"stdout","text":"6578/6578 [==============================] - 1474s 224ms/step - loss: 1.9220 - val_loss: 2.0097\nSebelumnya Overfitting\nEpoch 91/100\n6578/6578 [==============================] - 1468s 223ms/step - loss: 1.9245 - val_loss: 2.0134\nSebelumnya Overfitting\nEpoch 92/100\n6578/6578 [==============================] - 1520s 231ms/step - loss: 1.9227 - val_loss: 2.0125\nSebelumnya Overfitting\nEpoch 93/100\n6578/6578 [==============================] - 1463s 222ms/step - loss: 1.9204 - val_loss: 2.0215\nSebelumnya Overfitting\nEpoch 94/100\n6578/6578 [==============================] - 1466s 223ms/step - loss: 1.9198 - val_loss: 2.0138\nSebelumnya Overfitting\nEpoch 95/100\n6578/6578 [==============================] - 1465s 223ms/step - loss: 1.9208 - val_loss: 2.0239\nSebelumnya Overfitting\nEpoch 96/100\n6578/6578 [==============================] - 1464s 223ms/step - loss: 1.9219 - val_loss: 2.0047\nSebelumnya Overfitting\nEpoch 97/100\n6578/6578 [==============================] - 1476s 224ms/step - loss: 1.9191 - val_loss: 2.0255\nSebelumnya Overfitting\nEpoch 98/100\n6578/6578 [==============================] - 1478s 225ms/step - loss: 1.9184 - val_loss: 2.0072\nSebelumnya Overfitting\nEpoch 99/100\n6578/6578 [==============================] - 1481s 225ms/step - loss: 1.9161 - val_loss: 2.0126\nSebelumnya Overfitting\nEpoch 100/100\n6578/6578 [==============================] - 1479s 225ms/step - loss: 1.9183 - val_loss: 2.0056\nSebelumnya Overfitting\n","output_type":"stream"}]},{"cell_type":"code","source":"t=0\nwhile(t<1):\n    t=t","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:23:53.969158Z","iopub.execute_input":"2021-12-29T21:23:53.969494Z","iopub.status.idle":"2021-12-30T01:04:02.373291Z","shell.execute_reply.started":"2021-12-29T21:23:53.969455Z","shell.execute_reply":"2021-12-30T01:04:02.369189Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1653830578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#metadata_cache = '/kaggle/input/dataset91/train.pickle'\n#with open(metadata_cache, 'rb') as handle:\n#    train = pickle.load(handle)\n#metadata_cache = '/kaggle/input/dataset91/validation.pickle'\n#with open(metadata_cache, 'rb') as handle:\n#    validation = pickle.load(handle)\nimport pickle5 as pickle\nmetadata_cache = '/kaggle/input/fp2021/competition-test.pickle'\nwith open(metadata_cache, 'rb') as handle:\n    competition_test = pickle.load(handle)\ntrain_labels=np.load('/kaggle/input/fp2021/train-labels.npy')\nvalidation_labels=np.load('/kaggle/input/fp2021/validation-labels.npy')\ncompetition_test_labels=np.load('/kaggle/input/fp2021/competition-test-labels.npy')\nprint(\"HASIL EVALUASI MODEL-INPUT 82 Full Fitur\")\nprint(\" \")\ntest_predictions = model.predict(process_features(competition_test))\nprint(\"Mean Haversine Test:{}\".format(np_haversine(test_predictions, competition_test_labels).mean()))\nvalidation_predictions = model.predict(validation)\nprint(\"Mean Haversine Validation:{}\".format(np_haversine(validation_predictions, validation_labels).mean()))\ntrain_predictions = model.predict(train)\nprint(\"Mean Haversine Train:{}\".format(np_haversine(train_predictions, train_labels).mean()))\nprint(\" \")\ny_train=train_labels\ny_train_pred=train_predictions\ny_valid=validation_labels\ny_valid_pred=validation_predictions\ny_test=competition_test_labels\ny_test_pred=test_predictions\nfrom sklearn import metrics\nprint(\"MSE train:{}\".format(metrics.mean_squared_error(y_train, y_train_pred)))\nprint(\"MSE validation:{}\".format(metrics.mean_squared_error(y_valid, y_valid_pred)))\nprint(\"MSE test:{}\".format(metrics.mean_squared_error(y_test, y_test_pred)))\nprint(\" \")\nprint(\"MAE score train:{}\".format(metrics.mean_absolute_error(y_train, y_train_pred)))\nprint(\"MAE score validation:{}\".format(metrics.mean_absolute_error(y_valid, y_valid_pred)))\nprint(\"MAE score test:{}\".format(metrics.mean_absolute_error(y_test, y_test_pred)))\nprint(\" \")\nprint(\"R2 score train:{}\".format(metrics.r2_score(y_train, y_train_pred)))\nprint(\"R2 score validation:{}\".format(metrics.r2_score(y_valid, y_valid_pred)))\nprint(\"R2 score test:{}\".format(metrics.r2_score(y_test, y_test_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T01:04:02.378091Z","iopub.status.idle":"2021-12-30T01:04:02.378828Z","shell.execute_reply.started":"2021-12-30T01:04:02.378575Z","shell.execute_reply":"2021-12-30T01:04:02.378604Z"},"trusted":true},"execution_count":null,"outputs":[]}]}