{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"../input/dataset91/data.py\", dst = \"../working/data.py\")\ncopyfile(src = \"../input/dataset91/utils.py\", dst = \"../working/utils.py\")\ncopyfile(src = \"../input/dataset91/training.py\", dst = \"../working/training.py\")\ncopyfile(src = \"../input/dataset91/layers.py\", dst = \"../working/layers.py\")\n#copyfile(src = \"../input/notes1/weights2.npy\", dst = \"../working/weights2.npy\")\n# import all our functions\n#from data import load_data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-17T14:14:04.787114Z","iopub.execute_input":"2021-12-17T14:14:04.787422Z","iopub.status.idle":"2021-12-17T14:14:04.804753Z","shell.execute_reply.started":"2021-12-17T14:14:04.787391Z","shell.execute_reply":"2021-12-17T14:14:04.804060Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'../working/layers.py'"},"metadata":{}}]},{"cell_type":"code","source":"# Estimate the GPS clusters\nprint(\"Estimating clusters...\")\n#clusters = get_clusters(data.train_labels)\nn_epochs=100\nbatch_size=200\nsave_prefix='mymodel'\nconfig=3\n","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:04.806703Z","iopub.execute_input":"2021-12-17T14:14:04.806954Z","iopub.status.idle":"2021-12-17T14:14:04.813674Z","shell.execute_reply.started":"2021-12-17T14:14:04.806920Z","shell.execute_reply":"2021-12-17T14:14:04.812821Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Estimating clusters...\n","output_type":"stream"}]},{"cell_type":"code","source":"#import pickle\n!pip install pickle5\nimport csv\nimport calendar\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import  MultipleLocator, FormatStrFormatter\nfrom scipy.interpolate import splrep\nfrom IPython.core.display import display_html\nfrom keras.models import load_model\nfrom utils import np_haversine, density_map, get_clusters, plot_embeddings\nfrom data import load_data\n#from training import start_new_session, process_features, create_model\n\n# Display plots inline\n%matplotlib inline\n\n# Fix random seed for reproducibility\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:04.815084Z","iopub.execute_input":"2021-12-17T14:14:04.815571Z","iopub.status.idle":"2021-12-17T14:14:11.960433Z","shell.execute_reply.started":"2021-12-17T14:14:04.815513Z","shell.execute_reply":"2021-12-17T14:14:11.959459Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pickle5 in /opt/conda/lib/python3.7/site-packages (0.0.12)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def start_new_session():\n    \"\"\"\n    Starts a new Tensorflow session.\n    \"\"\"\n    \n    # Make sure the session only uses the GPU memory that it actually needs\n    config = tf.compat.v1.ConfigProto()\n    config.gpu_options.allow_growth = True\n    \n    session = tf.compat.v1.Session(config=config, graph=tf.compat.v1.get_default_graph())\n    tf.compat.v1.keras.backend.set_session(session)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:11.963437Z","iopub.execute_input":"2021-12-17T14:14:11.964069Z","iopub.status.idle":"2021-12-17T14:14:11.971871Z","shell.execute_reply.started":"2021-12-17T14:14:11.964024Z","shell.execute_reply":"2021-12-17T14:14:11.971212Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"clusters_cache = '/kaggle/input/dataset91/clusters.npy'\nclusters=np.load(clusters_cache, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:11.974825Z","iopub.execute_input":"2021-12-17T14:14:11.975089Z","iopub.status.idle":"2021-12-17T14:14:11.985089Z","shell.execute_reply.started":"2021-12-17T14:14:11.975055Z","shell.execute_reply":"2021-12-17T14:14:11.984371Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"file='/kaggle/input/dataset91/train0.npy'\ntrain0=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train1.npy'\ntrain1=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train2.npy'\ntrain2=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train3.npy'\ntrain3=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train4.npy'\ntrain4=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train5.npy'\ntrain5=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/train6.npy'\ntrain6=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\ntrain=[train0,train1,train2,train3,train4,train5,train6]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:11.986660Z","iopub.execute_input":"2021-12-17T14:14:11.987113Z","iopub.status.idle":"2021-12-17T14:14:12.119585Z","shell.execute_reply.started":"2021-12-17T14:14:11.987067Z","shell.execute_reply":"2021-12-17T14:14:12.117289Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"file='/kaggle/input/dataset91/validation0.npy'\nvalidation0=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation1.npy'\nvalidation1=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation2.npy'\nvalidation2=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation3.npy'\nvalidation3=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation4.npy'\nvalidation4=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation5.npy'\nvalidation5=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nfile='/kaggle/input/dataset91/validation6.npy'\nvalidation6=np.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\nvalidation=[validation0,validation1,validation2,validation3,validation4,validation5,validation6]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:12.121919Z","iopub.execute_input":"2021-12-17T14:14:12.122200Z","iopub.status.idle":"2021-12-17T14:14:12.165059Z","shell.execute_reply.started":"2021-12-17T14:14:12.122131Z","shell.execute_reply":"2021-12-17T14:14:12.164230Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"!pip3 install pickle5\nimport pickle5 as pickle\nmetadata_cache = '/kaggle/input/dataset91/metadata.pickle'\nwith open(metadata_cache, 'rb') as handle:\n    metadata = pickle.load(handle)\ntl_cache = '/kaggle/input/dataset91/train-labels.npy'\nvl_cache = '/kaggle/input/dataset91/validation-labels.npy'\ntrain_labels=np.load(tl_cache, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\nvalidation_labels=np.load(vl_cache, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:12.166957Z","iopub.execute_input":"2021-12-17T14:14:12.167500Z","iopub.status.idle":"2021-12-17T14:14:20.061462Z","shell.execute_reply.started":"2021-12-17T14:14:12.167461Z","shell.execute_reply":"2021-12-17T14:14:20.060583Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pickle5 in /opt/conda/lib/python3.7/site-packages (0.0.12)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import scale\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD, Adam, Adagrad\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.core import Dense, Reshape, Activation, Dropout\nfrom keras.layers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom utils import tf_haversine\nfrom data import load_data\nfrom utils import get_clusters\nfrom keras.models import Model\n\nfrom tensorflow.compat.v1.keras.layers import LSTM   # CuDNNLSTM\nfrom tensorflow.compat.v1.keras.layers import GRU\nimport sys\nsys.path.append('..')  # add parent directory to Python path for layers.py access\nfrom layers import Attention, SelfAttention\n\ndef create_model(metadata,clusters,config):\n    \"\"\"\n    Creates all the layers for our neural network model.\n    \"\"\"\n      \n    # Arbitrary dimension for all embeddings\n    embedding_dim = 10\n\n    # Quarter hour of the day embedding\n    embed_quarter_hour = Sequential()\n    embed_quarter_hour.add(Embedding(metadata['n_quarter_hours'], embedding_dim, input_length=1))\n    embed_quarter_hour.add(Reshape((embedding_dim,1)))\n\n    # Day of the week embedding\n    embed_day_of_week = Sequential()\n    embed_day_of_week.add(Embedding(metadata['n_days_per_week'], embedding_dim, input_length=1))\n    embed_day_of_week.add(Reshape((embedding_dim,1)))\n\n    # Week of the year embedding\n    embed_week_of_year = Sequential()\n    embed_week_of_year.add(Embedding(metadata['n_weeks_per_year'], embedding_dim, input_length=1))\n    embed_week_of_year.add(Reshape((embedding_dim,1)))\n\n    # Client ID embedding\n    embed_client_ids = Sequential()\n    embed_client_ids.add(Embedding(metadata['n_client_ids'], embedding_dim, input_length=1))\n    embed_client_ids.add(Reshape((embedding_dim,1)))\n\n    # Taxi ID embedding\n    embed_taxi_ids = Sequential()\n    embed_taxi_ids.add(Embedding(metadata['n_taxi_ids'], embedding_dim, input_length=1))\n    embed_taxi_ids.add(Reshape((embedding_dim,1)))\n\n    # Taxi stand ID embedding\n    embed_stand_ids = Sequential()\n    embed_stand_ids.add(Embedding(metadata['n_stand_ids'], embedding_dim, input_length=1))\n    embed_stand_ids.add(Reshape((embedding_dim,1)))\n    \n    # GPS coordinates (5 first lat/long and 5 latest lat/long, therefore 20 values)\n    coords = Sequential()\n    coords.add(Dense(1, input_dim=20))\n\n    # Merge all the inputs into a single input layer\n    mergedOut = Add()([embed_quarter_hour.output,\n                embed_day_of_week.output,\n                embed_week_of_year.output,\n                embed_client_ids.output,\n                embed_taxi_ids.output,\n                embed_stand_ids.output,\n                coords.output])\n    \n    #encoder_output, hidden_state, cell_state = LSTM(50, activation='tanh',input_shape=(None,None, 1),\n    #                                                return_sequences=True,return_state=True)(mergedOut)\n    #attention_input = [encoder_output, hidden_state]\n    gru_layer=tf.keras.layers.GRU(200, return_sequences=True,return_state=True)\n    if config != 0:\n        #encoder_output, hidden_state, cell_state = LSTM(units=200,\n        #                                                 return_sequences=True\n        #                                                ,return_state=True#,input_shape=(50,1)\n        #                                               )(mergedOut)\n        encoder_output, hidden_state, cell_state = Bidirectional(gru_layer,\n                                                                      merge_mode=\"sum\")(mergedOut)\n        attention_input = [encoder_output, hidden_state]\n    else:\n        encoder_output = LSTM(units=64)(mergedOut)\n\n    # Optional Attention Mechanisms\n    if config == 1:\n        encoder_output, attention_weights = SelfAttention(size=64,\n                                                      num_hops=10,\n                                                      use_penalization=False)(encoder_output)\n    elif config == 2:\n        encoder_output, attention_weights = Attention(context='many-to-one',\n                                                  alignment_type='global')(attention_input)\n        encoder_output = Flatten()(encoder_output)\n    elif config == 3:\n        encoder_output, attention_weights = Attention(context='many-to-one',\n                                                  alignment_type='local-m',\n                                                  window_width=10,\n                                                  score_function='general')(attention_input)\n        encoder_output = Flatten()(encoder_output)\n        \n    \n    #encoder_output=Dense(1)(encoder_output)\n    # Determine cluster probabilities using softmax\n    mergedOut=Dense(len(clusters))(encoder_output)\n    mergedOut=Activation('softmax')(mergedOut)\n\n    # Final activation layer: calculate the destination as the weighted mean of cluster coordinates\n    cast_clusters = K.cast_to_floatx(clusters)\n    def destination(probabilities):\n        return tf.matmul(probabilities, cast_clusters)\n    mergedOut=Activation(destination)(mergedOut)\n\n    newModel = Model([embed_quarter_hour.input,\n                embed_day_of_week.input,\n                embed_week_of_year.input,\n                embed_client_ids.input,\n                embed_taxi_ids.input,\n                embed_stand_ids.input,\n                coords.input], mergedOut)\n    #use lists if you want more than one input or output  \n    \n    # Compile the model\n    optimizer = SGD(lr=0.1, momentum=0.9, clipvalue=1.)  # Use `clipvalue` to prevent exploding gradients\n\n    newModel.compile(loss=tf_haversine, optimizer=optimizer)\n    \n    return newModel","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.063562Z","iopub.execute_input":"2021-12-17T14:14:20.063802Z","iopub.status.idle":"2021-12-17T14:14:20.090465Z","shell.execute_reply.started":"2021-12-17T14:14:20.063773Z","shell.execute_reply":"2021-12-17T14:14:20.089705Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model=create_model(metadata,clusters,config)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.091706Z","iopub.execute_input":"2021-12-17T14:14:20.092677Z","iopub.status.idle":"2021-12-17T14:14:20.621571Z","shell.execute_reply.started":"2021-12-17T14:14:20.092571Z","shell.execute_reply":"2021-12-17T14:14:20.620848Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.622774Z","iopub.execute_input":"2021-12-17T14:14:20.623022Z","iopub.status.idle":"2021-12-17T14:14:20.642454Z","shell.execute_reply.started":"2021-12-17T14:14:20.622989Z","shell.execute_reply":"2021-12-17T14:14:20.641672Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nembedding_12_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_13_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_14_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_15_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_16_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_17_input (InputLayer) [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding_12 (Embedding)        (None, 1, 10)        960         embedding_12_input[0][0]         \n__________________________________________________________________________________________________\nembedding_13 (Embedding)        (None, 1, 10)        70          embedding_13_input[0][0]         \n__________________________________________________________________________________________________\nembedding_14 (Embedding)        (None, 1, 10)        520         embedding_14_input[0][0]         \n__________________________________________________________________________________________________\nembedding_15 (Embedding)        (None, 1, 10)        570940      embedding_15_input[0][0]         \n__________________________________________________________________________________________________\nembedding_16 (Embedding)        (None, 1, 10)        4440        embedding_16_input[0][0]         \n__________________________________________________________________________________________________\nembedding_17 (Embedding)        (None, 1, 10)        640         embedding_17_input[0][0]         \n__________________________________________________________________________________________________\ndense_4_input (InputLayer)      [(None, 20)]         0                                            \n__________________________________________________________________________________________________\nreshape_12 (Reshape)            (None, 10, 1)        0           embedding_12[0][0]               \n__________________________________________________________________________________________________\nreshape_13 (Reshape)            (None, 10, 1)        0           embedding_13[0][0]               \n__________________________________________________________________________________________________\nreshape_14 (Reshape)            (None, 10, 1)        0           embedding_14[0][0]               \n__________________________________________________________________________________________________\nreshape_15 (Reshape)            (None, 10, 1)        0           embedding_15[0][0]               \n__________________________________________________________________________________________________\nreshape_16 (Reshape)            (None, 10, 1)        0           embedding_16[0][0]               \n__________________________________________________________________________________________________\nreshape_17 (Reshape)            (None, 10, 1)        0           embedding_17[0][0]               \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 1)            21          dense_4_input[0][0]              \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 10, 1)        0           reshape_12[0][0]                 \n                                                                 reshape_13[0][0]                 \n                                                                 reshape_14[0][0]                 \n                                                                 reshape_15[0][0]                 \n                                                                 reshape_16[0][0]                 \n                                                                 reshape_17[0][0]                 \n                                                                 dense_4[0][0]                    \n__________________________________________________________________________________________________\nbidirectional_2 (Bidirectional) [(None, 10, 200), (N 243600      add_2[0][0]                      \n__________________________________________________________________________________________________\nattention_2 (Attention)         ((None, 10, 200), (N 40000       bidirectional_2[0][0]            \n                                                                 bidirectional_2[0][1]            \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 2000)         0           attention_2[0][0]                \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 5487)         10979487    flatten_2[0][0]                  \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 5487)         0           dense_5[0][0]                    \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 2)            0           activation_4[0][0]               \n==================================================================================================\nTotal params: 11,840,678\nTrainable params: 11,840,678\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"e=[]\nf=[]\ng=[]\nfor i in range(30):\n    f.append(0)\n    e.append(0)\n    g.append(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.643586Z","iopub.execute_input":"2021-12-17T14:14:20.643898Z","iopub.status.idle":"2021-12-17T14:14:20.649296Z","shell.execute_reply.started":"2021-12-17T14:14:20.643861Z","shell.execute_reply":"2021-12-17T14:14:20.648528Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class MyCallback(tf.keras.callbacks.Callback):\n    def on_train_end(self, logs=None):\n        global training_finished\n        training_finished = True\n    def on_epoch_end(self, epoch, logs=None):\n        z=len(e)\n        if z>len(g):\n            a=model.history.history['val_loss'][z-len(g)-1]\n            b=model.history.history['loss'][z-len(g)-1]\n            c=float(a)-float(b)\n            if c<0:\n                print(\"Sebelumnya Underfitting\")\n            else:\n                print(\"Sebelumnya Overfitting\")\n        e.append(0)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.650346Z","iopub.execute_input":"2021-12-17T14:14:20.650745Z","iopub.status.idle":"2021-12-17T14:14:20.659600Z","shell.execute_reply.started":"2021-12-17T14:14:20.650683Z","shell.execute_reply":"2021-12-17T14:14:20.658659Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class CustCallback(tf.keras.callbacks.Callback):\n    def on_train_end(self, logs=None):\n        global training_finished\n        training_finished = True\n    def on_epoch_end(self, epoch, logs=None):\n        z=len(f)\n        file_path=\"../working/Newweights\"+str(z)\n        weight=model.get_weights()\n        np.save(file_path, weight)\n        f.append(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.662967Z","iopub.execute_input":"2021-12-17T14:14:20.663200Z","iopub.status.idle":"2021-12-17T14:14:20.672311Z","shell.execute_reply.started":"2021-12-17T14:14:20.663148Z","shell.execute_reply":"2021-12-17T14:14:20.671515Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#file='../input/latbigru91fiturlocm/Newweights'+str(len(g)-1)+'.npy'\nfile='./Newweights'+str(len(g)-1)+'.npy'\nb=np.load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\nmodel.set_weights(b)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.674692Z","iopub.execute_input":"2021-12-17T14:14:20.676302Z","iopub.status.idle":"2021-12-17T14:14:20.811180Z","shell.execute_reply.started":"2021-12-17T14:14:20.676271Z","shell.execute_reply":"2021-12-17T14:14:20.810305Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file='../input/dataset91/train-labels.npy'\ntrain_labels=np.load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\nfile='../input/dataset91/validation-labels.npy'\nvalidation_labels=np.load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.812915Z","iopub.execute_input":"2021-12-17T14:14:20.813260Z","iopub.status.idle":"2021-12-17T14:14:20.832050Z","shell.execute_reply.started":"2021-12-17T14:14:20.813217Z","shell.execute_reply":"2021-12-17T14:14:20.831221Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, CSVLogger\nfrom keras.callbacks import EarlyStopping\n \ncallbacks = []\nif save_prefix is not None:\n        # Save the model's intermediary weights to disk after each epoch\n    file_path=\"cache/%s-{epoch:03d}-{val_loss:.4f}.hdf5\" % save_prefix\n    checkpoint = ModelCheckpoint(file_path,monitor='val_loss',mode='auto',save_weights_only=True,verbose=0)\n    #checkpoint = weight_save(model.get_weights(),b)\n    callbacks.append(checkpoint)\n    #callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', mode='min', save_weights_only=True, verbose=1))\n    #callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', verbose=0, save_best_only=False, mode='auto'))\n    #model.fit(X_train,y_train,batch_size=batch_size,nb_epoch=nb_epoch,callbacks=[weight_save_callback])\n#g.append(0)\n#epoch>1\n\n#first epoch\n#saver = weight_save(model.get_weights(),b)   \n#es = EarlyStopping(monitor='val_loss', patience=0, verbose=1)\narc='LATBiGRUnew91-b200-'+str(len(g))+'.log'\ncsv_logger = CSVLogger(arc, separator=',', append=False)\nprint(\"Creating model...\")\nstart_new_session()\nprint(\"Train model...\")\nhistory=model.fit(train, train_labels,\n        initial_epoch=len(g),epochs=100, batch_size=batch_size,\n        validation_data=(validation, validation_labels)\n        ,callbacks=[csv_logger,CustCallback(),MyCallback()])","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:14:20.833779Z","iopub.execute_input":"2021-12-17T14:14:20.834347Z","iopub.status.idle":"2021-12-17T14:25:17.588508Z","shell.execute_reply.started":"2021-12-17T14:14:20.834306Z","shell.execute_reply":"2021-12-17T14:25:17.586616Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Creating model...\nTrain model...\n","output_type":"stream"},{"name":"stderr","text":"2021-12-17 14:14:20.842522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-17 14:14:20.843868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-17 14:14:20.844741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-17 14:14:20.845589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-17 14:14:20.846335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-12-17 14:14:20.846934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/100\n","output_type":"stream"},{"name":"stderr","text":"2021-12-17 14:14:24.288335: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 16152002560 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n","output_type":"stream"},{"name":"stdout","text":"7397/7400 [============================>.] - ETA: 0s - loss: 1.9864","output_type":"stream"},{"name":"stderr","text":"2021-12-17 14:15:53.324950: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla P100-PCIE-16GB\" frequency: 1328 num_cores: 56 environment { key: \"architecture\" value: \"6.0\" } environment { key: \"cuda\" value: \"11000\" } environment { key: \"cudnn\" value: \"8005\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 16152002560 bandwidth: 732160000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n","output_type":"stream"},{"name":"stdout","text":"7400/7400 [==============================] - 96s 13ms/step - loss: 1.9864 - val_loss: 2.0273\nEpoch 32/100\n7400/7400 [==============================] - 91s 12ms/step - loss: 1.9872 - val_loss: 2.0334\nSebelumnya Overfitting\nEpoch 33/100\n7400/7400 [==============================] - 92s 12ms/step - loss: 1.9865 - val_loss: 2.0376\nSebelumnya Overfitting\nEpoch 34/100\n7400/7400 [==============================] - 92s 12ms/step - loss: 1.9864 - val_loss: 2.0399\nSebelumnya Overfitting\nEpoch 35/100\n7400/7400 [==============================] - 91s 12ms/step - loss: 1.9817 - val_loss: 2.0248\nSebelumnya Overfitting\nEpoch 36/100\n7400/7400 [==============================] - 91s 12ms/step - loss: 1.9807 - val_loss: 2.0257\nSebelumnya Overfitting\nEpoch 37/100\n7400/7400 [==============================] - 91s 12ms/step - loss: 1.9826 - val_loss: 2.0189\nSebelumnya Overfitting\nEpoch 38/100\n 905/7400 [==>...........................] - ETA: 1:16 - loss: 1.9855","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_53/1298233623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         ,callbacks=[csv_logger,CustCallback(),MyCallback()])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"t=0\nwhile(t<1):\n    t=t","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:25:17.589285Z","iopub.status.idle":"2021-12-17T14:25:17.589587Z","shell.execute_reply.started":"2021-12-17T14:25:17.589438Z","shell.execute_reply":"2021-12-17T14:25:17.589457Z"},"trusted":true},"execution_count":null,"outputs":[]}]}